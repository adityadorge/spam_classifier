{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import urllib\n",
    "import tarfile\n",
    "import numpy as np\n",
    "# import quopri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urllib and tarfile are pre-installed in python > urllib used to for files/website related operations & tarfile is used for zip file related operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from: https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
      "Saving to: /home/t460/Documents/ollama/datasets/spam/20021010_easy_ham.tar.bz2\n",
      "Downloading from: https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
      "Saving to: /home/t460/Documents/ollama/datasets/spam/20021010_spam.tar.bz2\n",
      "/home/t460/Documents/ollama/datasets/spam/easy_ham\n",
      "/home/t460/Documents/ollama/datasets/spam/spam\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "def fetch_data(base_url, files,download_path):\n",
    "    for file in files:\n",
    "        # Construct the full URL\n",
    "        file_url = f\"{base_url}{file}\"\n",
    "        file_download_path = os.path.join(download_path, file)\n",
    "        print(f\"Downloading from: {file_url}\")\n",
    "        print(f\"Saving to: {file_download_path}\")\n",
    "\n",
    "        # Download and save the file\n",
    "        # try:\n",
    "        #     # Download the file\n",
    "        #     urllib.request.urlretrieve(file_url, file_download_path)\n",
    "        #     print(f\"File successfully downloaded and saved as {file_download_path}\")\n",
    "\n",
    "        #     # Verify the file is a valid .tar.bz2 and extract it\n",
    "        #     with tarfile.open(file_download_path, \"r:bz2\") as tar:\n",
    "        #         tar.extractall(path=download_path)\n",
    "        #         print(f\"Files successfully extracted to {download_path}\")\n",
    "        # except tarfile.TarError as e:\n",
    "        #     print(f\"TarError while extracting {file}: {e}\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"An error occurred: {e}\")\n",
    "\n",
    "    return [os.path.join(download_path,dir_name) for dir_name in (\"easy_ham\", \"spam\")] \n",
    "\n",
    "# Define the base URL, file names, and download path\n",
    "base_url = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "download_path = \"/home/t460/Documents/ollama/datasets/spam/\" # (absoulte path) Instead can use !from pathlib import Path\n",
    "files = [\"20021010_easy_ham.tar.bz2\", \"20021010_spam.tar.bz2\"]\n",
    "\n",
    "# Ensure the download directory exists\n",
    "# os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Fetch and extract the data\n",
    "ham_dir , spam_dir = fetch_data(base_url, files, download_path)\n",
    "print(ham_dir)\n",
    "print(spam_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the structure of the email. Creating dataset which consist of filtered hams&spams to feed to the model.<br>\n",
    "The dataset should consist of 4 :\n",
    "- sender's email and other important fields\n",
    "- subject\n",
    "- content of the email : Email contains HTML content or is a plain-text email, you can inspect the MIME type of its body parts. This can be done using Python's email module.\n",
    "- and a column stating is it spam or ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.policy import default\n",
    "from email.parser import BytesParser\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to extract email content (plain text or fallback to HTML)\n",
    "def get_email_content(email):\n",
    "    for part in email.walk():\n",
    "        html = None\n",
    "        ctype = part.get_content_type()\n",
    "        if not ctype in (\"text/plain\", \"text/html\"): # if content_type is other than plain text or html than ignore\n",
    "            continue\n",
    "        try:\n",
    "            # get the character dataset for emails\n",
    "            charset = part.get_content_charset() or \"utf-8\"  # Default to UTF-8\n",
    "            # extract the content with respect to that charaset else throws error of \"string argument should contain only ASCII characters\"\n",
    "            content = part.get_payload(decode=True).decode(charset, errors=\"replace\")\n",
    "        except Exception as e:\n",
    "            content = part.get_payload(decode=True).decode(\"utf-8\", errors=\"replace\")  # Fallback\n",
    "        if ctype == \"text/plain\":\n",
    "            return content.strip()\n",
    "        else:\n",
    "            html = content\n",
    "    if html:\n",
    "        soup = BeautifulSoup(html, 'html.parser') #convert to beautifulsoup object\n",
    "        decoded_html_content = soup.get_text(separator=\"\\n\", strip=True) # extract the content from html\n",
    "        return decoded_html_content\n",
    "    \n",
    "# Function to parse email and extract fields\n",
    "def parse_email(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            email = BytesParser(policy=default).parse(f)\n",
    "        \n",
    "        # Extract fields\n",
    "        email_data = {\n",
    "            #\"Receiver\": msg.get(\"Delivered-To\"),\n",
    "            \"From\": email.get(\"From\"),\n",
    "            #\"To\": msg.get(\"To\"),\n",
    "            \"Subject\": email.get(\"Subject\"),\n",
    "            \"Content\": get_email_content(email),\n",
    "        }\n",
    "        return email_data\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          From  \\\n",
      "0        Chris Kloiber <ckloiber@ckloiber.com>   \n",
      "1      Dermot Daly <dermot.daly@itsmobile.com>   \n",
      "2             Owen Byrne <owen@permafrost.net>   \n",
      "3              Glen Gray <glen@netnoteinc.com>   \n",
      "4  Eirikur Hallgrimsson <eh@mad.scientist.com>   \n",
      "\n",
      "                                             Subject  \\\n",
      "0                      Re: RH 8 no DMA for DVD drive   \n",
      "1                 [ILUG] What HOWTOs for SOHO system   \n",
      "2                              Re: The case for spam   \n",
      "3  [ILUG] Retrieving read mail from webmail.eirco...   \n",
      "4                              process music: Mekons   \n",
      "\n",
      "                                             Content Label  \n",
      "0  On Mon, 2002-10-07 at 13:28, Matthias Saou wro...   ham  \n",
      "1  Hi All,\\nI'm trying to set up the following:\\n...   ham  \n",
      "2  Bill Stoddard wrote:\\n\\n>>No one likes commerc...   ham  \n",
      "3  Is there a way to get my read email downloaded...   ham  \n",
      "4  http://reuters.com/news_article.jhtml?type=ent...   ham  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Load emails and extract fields\n",
    "def process_email_directory(directory):\n",
    "    emails = []\n",
    "    for file_path in directory.iterdir():\n",
    "        if file_path.is_file():\n",
    "            email_data = parse_email(file_path)\n",
    "            if email_data:\n",
    "                emails.append(email_data)\n",
    "    return emails\n",
    "\n",
    "# Path to email directories\n",
    "ham_dir = Path(ham_dir)\n",
    "spam_dir = Path(spam_dir)\n",
    "\n",
    "# Process ham and spam directories\n",
    "ham_emails = process_email_directory(ham_dir)\n",
    "spam_emails = process_email_directory(spam_dir)\n",
    "\n",
    "#______________________________________________________XXXXXX_________________________________________________________\n",
    "\n",
    "# Combine ham and spam emails into a single dataset\n",
    "email_data = pd.DataFrame(ham_emails + spam_emails)\n",
    "\n",
    "\n",
    "# Add labels for classification\n",
    "email_data[\"Label\"] = [\"ham\"] * len(ham_emails) + [\"spam\"] * len(spam_emails)\n",
    "\n",
    "# Save to CSV for model training\n",
    "# email_data.to_csv(\"email_dataset.csv\", index=False)\n",
    "\n",
    "print(email_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing Values with the most frequent values of each columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14457/1130259558.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  email_data[column].fillna(email_data[column].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# check the most frequent values of each columns \n",
    "# for column in email_data.columns:\n",
    "#     print(email_data[column].mode()[0])\n",
    "\n",
    "# Replacing missing values with the most common values of each column\n",
    "for column in email_data.columns:\n",
    "    email_data[column].fillna(email_data[column].mode()[0], inplace=True)  \n",
    "\n",
    "# # Saving the updated DataFrame to a CSV file\n",
    "# email_data.to_csv(\"email_dataset2.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_data = pd.read_csv('email_dataset.csv')\n",
    "X = email_data.drop('Label',axis=1)\n",
    "y = email_data['Label'] \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test =  train_test_split(X,y,test_size=0.2,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing step :\n",
    "- <span style=\"color:orange\"> Tokenization: </span> Split text into words or subwords.\n",
    "- <span style=\"color:orange\"> Normalization: </span> Lowercase, remove punctuation, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78     ive just gotton myself a modem (no its not a w...\n",
      "29     > So now Osama bin Laden is Hitler. And Saddam...\n",
      "280    Eirikur Hallgrimsson wrote:\\n> It's official, ...\n",
      "Name: Content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from urlextract import URLExtract  # Ensure the package is installed\n",
    "from collections import Counter\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize URL extractor\n",
    "url_extractor = URLExtract()\n",
    "\"\"\"\n",
    "def email_transform(sent):\n",
    "    # Process the email content\n",
    "\n",
    "    doc = nlp(sent)\n",
    "    filtered_words = []\n",
    "\n",
    "    for token in doc:\n",
    "        # Extract and replace URLs with \"URL\"\n",
    "        if url_extractor.has_urls(token.text):  # Checks if the token contains a URL\n",
    "            filtered_words.append(\"url\")\n",
    "        elif token.like_num:\n",
    "            filtered_words.append(\"number\")\n",
    "        elif token.is_alpha and not token.is_stop:  # Remove stopwords and keep only text\n",
    "            filtered_words.append(token.lemma_.lower())\n",
    "\n",
    "    return filtered_words\n",
    "\"\"\"\n",
    "\n",
    "def email_transform(sent):\n",
    "    for email in X:\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)\n",
    "\n",
    "# Transform the email content\n",
    "sample_train_email = X_train['Content'][:3]\n",
    "print(sample_train_email)\n",
    "\n",
    "# for i in sample_train_email:\n",
    "#     print(i)\n",
    "#     break\n",
    "    # processed_email = email_transform(i)\n",
    "    # print(f'Processed Email:{processed_email}')\n",
    "    # word_counter = Counter()\n",
    "    # for email in processed_email:\n",
    "    #     word_counter.update(email.split())\n",
    "    # print(\"Word Frequencies:\")\n",
    "    # print(f'{word_counter}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from urlextract import URLExtract  # Ensure the package is installed\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "\n",
    "class CustomEmailTransformer(BaseEstimator , TransformerMixin):  # for subject and content\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.url_extractor = URLExtract()\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        \n",
    "        X_transformed_word = []\n",
    "        for i in X:\n",
    "            transformed_word = [] # if want array's of counter\n",
    "            doc = self.nlp(i)\n",
    "            for token in doc:\n",
    "                # Extract and replace URLs with \"URL\"\n",
    "                if self.url_extractor.has_urls(token.text):  # Checks if the token contains a URL\n",
    "                    transformed_word.append(\"url\")\n",
    "                elif token.like_num:\n",
    "                    transformed_word.append(\"number\")\n",
    "                elif token.is_alpha and not token.is_stop:  # Remove stopwords and keep only text\n",
    "                    transformed_word.append(token.lemma_.lower())\n",
    "\n",
    "                word_counter = Counter()\n",
    "                for email in transformed_word: # Count word frequencies\n",
    "                    word_counter.update(email.split())\n",
    "            X_transformed_word.append(word_counter)\n",
    "\n",
    "        return np.array(X_transformed_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies:\n",
      "[Counter({'ilug': 1, 'modem': 1, 'problems': 1})\n",
      " Counter({'zzzzteana': 1, 'coming': 1, 'firestorm': 1})\n",
      " Counter({'holiday': 1, 'season': 1, 'number': 1, 'begin': 1})]\n"
     ]
    }
   ],
   "source": [
    "sample_train_content = X_train['Subject'][:3]\n",
    "\n",
    "word_count = CustomEmailTransformer().fit_transform(sample_train_content)\n",
    "\n",
    "# for i in sample_train_content:\n",
    "#     word_count = transformer .transform(i)\n",
    "print(\"Word Frequencies:\")\n",
    "print(f'{word_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform the \"From\" feature column : extract the domain name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Domains:\n",
      "['redpie.com', 'ee.ed.ac.uk', 'barrera.org', 'mail.com', 'none.com', 'yahoo.com', 'example.com', 'example.com', 'indiatimes.com', 'docserver.cac.washington.edu', 'qu.to', 'wanadoo.fr', 'silcom.com', 'iol.ie', 'arabia.com', 'insiq.us', 'punkass.com', 'ig.com.br', 'noskillz.com', 'email.com', 'barrera.org', 'iol.ie', 'yahoo.com', 'svanstrom.com', 'example.com', 'hotmail.com', 'permafrost.net', 'sunglasses.com', 'mithral.com', 'insiq.us', 'subdimension.com', 'slack.net', 'caramail.com', 'evergo.net', 'insiq.us', 'shipwright.com', 'cursor-system.com', 'techmonkeys.net', 'framesetup.com', 'example.com', 'reset.jp', 'netnoteinc.com', 'eircom.net', 'yelsew.com', 'etang.com', 'interszkola.pl', 'shipwright.com', 's3.serveimage.com', 'infinetivity.com', 'iol.ie', 'att.net', 'deepeddy.com', 'eecs.berkeley.edu', 'hotmail.com', 'slack.net', 'alltel.net', 'mx03.readyserve21.com', 'btamail.net.cn', 'corvil.com', 'argote.ch', 'frogstone.net', 'tuatha.org', 'srv0.ems.ed.ac.uk', 'accesocero.es', 'tuatha.org', '99-81.com', 'clubi.ie', 'hotmail.com', '2ubh.com', 'chinaemail.net', 'endeavors.com', 'firemail.de', 'mobiusvc.com', 'shipwright.com', 'canada.com', 'bellsouth.net', 'eircom.net', 'yahoo.com', 'bacalhau.com.br', 'mail.banirh.com', 'mail.com', 'endeavors.com', 'terra.es', 'bestirishmusic.com', 'alumni.caltech.edu', 'hotmail.com', 'dogma.slashnull.org', 'hotmail.com', 'earthlink.net', 'petting-zoo.net', 'bluemail.dk', 'eecs.berkeley.edu', 'sunglasses.com', 'caramail.com', 'sbox.tu-graz.ac.at', 'enews.com.tw', 'flashmail.com', 'email2.qves.net', 'cse.ucsc.edu', 'shipwright.com', 'barrera.org', 'eudoramail.com', 'usa.net', 'aol.com', 'munnari.oz.au', 'yahoo.com', 'yahoo.fr', 'yahoo.fr', 'hotmail.com', '360cn.com', 'sendgreatoffers.com', 'frugaljoe.com', 'yahoo.com', 'yahoo.com', 'insiq.us', 'bennewitz.com', 'hotmail.com', 'ckloiber.com', 'terra.es', 'aol.com', 'perl.org', 'baesystems.com', 'corvil.com', '2ubh.com', 'yahoo.com', 'srv0.ems.ed.ac.uk', 'flashmail.com', 'ulysees.com', 'caramail.com', 'l8.newnamedns.com', 'munnari.oz.au', 'acsmsupplies.com', 'baesystems.com', 'friendsearch.com', 'lycos.com', 'ckloiber.com', 'stevek.com', 'top10.bestoffersonthenet.com', 'cheapsmoking.com', 'yahoo.com', 'yahoo.com', 'frogstone.net', 'bigfoot.com', 'leitl.org', 'srv0.ems.ed.ac.uk', 'lbedford.org', 'endeavors.com', 'hotmail.com', 'yahoo.com', 'physik.fu-berlin.de', 'sendgreatoffers.com', 'barrera.org', 'slack.net', 'l1.newnamedns.com', 'waider.ie', 'canada.com', 'best.com', 'hackwatch.com', 'yahoo.com', 'maxtor.com', 'mithral.com', 'frogstone.net', 'excite.com', 'barrera.org', 'hotmail.com', 'evergo.net', 'victoria.tc.ca', 'spinfinder.com', '2ubh.com', 'mail.com', 'gmx.at', 'perl.org', 'example.com', 'endeavors.com', 'eclipse.co.uk', 'r2-dvd.org', 's3.serveimage.com', 'torchlake.com', 'hotmail.com', 'l6.newnamedns.com', 'netscape.net', 'ucla.edu', 'punkass.com', 'maktoob.com', 'ucd.ie', 'srv0.ems.ed.ac.uk', 'canada.com', 'purplehotel.com', 'srv0.ems.ed.ac.uk', 'subdimension.com', 'linkgift.net', 'kamakiriad.com', 'canada.com', 'utt.ro', 'example.com', 'yahoo.com', 'sri.com', 'frugaljoe.com', 'spinfinder.com', 'georgia.co.jp', 'aol.com', 'pobox.com', 'cb.offermonkey.com', 'aernet.ru', 'dracnet.es', 'terra.es', 'webstakes.com', 'netscape.net', 'best.com', 'netnoteinc.com', 'yahoo.com', 'lycos.com', 'no.hostname.specified', 'eudoramail.com', '2ubh.com', 'framesetup.com', 'runbox.com', 'mail.gr', 'dogma.slashnull.org', 'l1.newnamedns.com', '2ubh.com', '2ubh.com', 'yahoo.com', 'ucd.ie', 'site-personals.com', 'hotmail.com', 'example.com', 'ee.ed.ac.uk', 'lanminds.com', 'example.com', 'techmonkeys.net', '2ubh.com', 'cse.ucsc.edu', 'magnesium.net', 'vccomputers.ie', 'welho.com', 'silcom.com', 'ul.ie', 'munnari.oz.au', 'panix.com', 'yahoo.com', 'ee.ed.ac.uk', 'top13.bestoffersonthenet.com', 'flashmail.com', 'sendgreatoffers.com', 'davicom.co.kr', 'chel.elektra.ru', 'missouri.co.jp', 'tuatha.org', 'yahoo.com', 'l5.newnamedns.com', 'martyrs.com.au', 'rediffmail.com', 'aol.com', 'endeavors.com', 'privacyright.com', 'eudoramail.com', 'flashmail.com', 'carrey.adgrafix.com', 'ianbell.com', 'ee.ed.ac.uk', 'cs.helsinki.fi', 'hotmail.com', 'hotmail.com', 'iafrica.com', 'rpmforge.net', 'slack.net', '2ubh.com', 'panasas.com', 'netscape.net', 'panix.com', 'slack.net', 'deepeddy.com', 'yahoo.com', 'evergo.net', 'leitl.org', 'juno.com', 'webstakes.com', 'kolaymail.com', 'abigclick.zzn.com', 'wanadoo.fr', 'hellerwhirligigs.com', 'waider.ie', 'magnesium.net', 'hotmail.com', 'offerclubmail.com', 'shipwright.com', 'slack.net', 'leitl.org', 'linuxmafia.com', 'srv0.ems.ed.ac.uk', 'megamail.pt', 'bluemail.dk', 'hotmail.com', 'aminvestments.com', 'shipwright.com', 'hp.com', 'permafrost.net', 'victoria.tc.ca', 'insiq.us', 'hotmail.com', 'jmason.org', 'egwn.net', 'waider.ie', 'hotmail.com', 'yahoo.com', 'hotmail.com', 'yahoo.com', 'mithral.com', 'wu-wien.ac.at', 'mymail.dk', 'wstoddard.com', 'linuxmafia.com', 'libero.it', 'topmail.dk', 'egwn.net', 'netscape.net', 'hotmail.com', 'iki.fi', 'mx03.readyserve21.com', 'aminvestments.com', 'lineone.net', 'redseven.de', 'freeuk.com', 'r2-dvd.org', '2ubh.com', '99-81.com', 'risingtidestudios.com', 'mithral.com', 'reply2.azoogle.com', 'ie.suberic.net', 'flashmail.com', '2ubh.com', 'hotmail.com', '2ubh.com', 'cheapsmoking.com', 'trackbike.com', 'ryanairmail.com', 'tuatha.org', 'hotmail.com', 'srv0.ems.ed.ac.uk', 'baesystems.com', 'eecs.berkeley.edu', 'redbrick.dcu.ie', 'munnari.oz.au', 'srv0.ems.ed.ac.uk', 'netscape.net', 'aol.com', 'l7.newnamedns.com', 'mindupmerchants.com', 'waider.ie', 'kamakiriad.com', 'pathname.com', 'newyork.com', 'mithral.com', 'aol.com', 'aol.com', 'hotmail.com', 'redbrick.dcu.ie', 'mad.scientist.com', 'deepeddy.com', 'orchidserve.com', 'yahoo.ca', 'mindspring.com', 'angelfire.com', 'rpmforge.net', 'eire.com', 'isppan.waw.pl', 'mithral.com', 'hughes-family.org', 'hotmail.com', 'hotmail.com', 'linuxworks.com.au', 'cursor-system.com', 'insiq.us', 'linkgift.net', 'slack.net', 'pobox.com', 'hotmail.com', 'monkey.org', 'argote.ch', 'idirect.net', 'bluemail.dk', 'ordersomewherechaos.com', 'mad.scientist.com', 'desertmail.com', 'synteligent.com', 'ttnet.net.tr', 'meritsolutions.ie', 'hotmail.com', 'caramail.com', 'bestirishmusic.com', 'waider.ie', 'eircom.net', 'insiq.us', 'eudoramail.com', 'cheerful.com', 'insiq.us', 'rpmforge.net', 'acm.org', 'actionsports.co.uk', 'caramail.com', 'msn.com', 'mediaunspun.imakenews.net', 'srv0.ems.ed.ac.uk', 'netsoc.ucd.ie', 'linux.ie', 'yahoo.com', 'yahoo.com', 'srv0.ems.ed.ac.uk', 'jtauber.com', 'terra.es', 'bluemail.dk', 'yahoo.com', 'ckloiber.com', 'hushmail.com', 'abigclick.zzn.com', 'hotmail.com', 'businez.com', 'europeaninternet.com', 'yahoo.com', 'rs.128.ne.jp', 'homeport.org', 'insiq.us', 'pobox.com', 'imail.ru', 'argote.ch', 'bellsouth.net', 'yahoo.com', 'r2-dvd.org', 'yahoo.co.uk', '360cn.com', 's3.serveimage.com', 'truthmail.com', 'best.com', 'linuxmafia.com', 'websitetracker.com', 'mail.com', 'ee.ed.ac.uk', 'esatclear.ie', 'insiq.us', 'example.com', 'post.com', 'wasptech.com', 'deepeddy.com', 'panix.com', 'mail.com', 'panix.com', 'barrera.org', 'usa.com', 'frugaljoe.com', '2nd-world.fr', 'hotmail.com', 'hotmail.com', 'l4.newnamedns.com', 'sendgreatoffers.com', 'lanminds.com', 'ant.eupvg.upc.es', 'yahoo.com', 'lists.tilw.net', 'fiaz.co.yu', 'pobox.com', 'totalise.co.uk', 'baesystems.com', 'caramail.com', 'sendgreatoffers.com', 'yahoo.com', 'example.com', '2ubh.com', 'consultant.com', 'eircom.net', 'redpie.com', 'frogstone.net', 'flashmail.com', 'webnote.net', 'hotmail.com', 'bigpond.com', 'r2-dvd.org', 'acm.org', '2ubh.com', 'exchange.ie.ml.com', '37.com', 'munnari.oz.au', 'insiq.us', 'datcon.co.uk', 'excite.com', 'dcu.ie', 'home-based-business.de', 'eware.com', 'mlug.missouri.edu', 'enenkio.org', 'hotmail.com', 'zip.com.au', '2ubh.com', 'deutsche-bank.de', 'eudoramail.com', 'sendgreatoffers.com', 'yahoo.com', 'ianbell.com', 'hotmail.com', 'staunton.ie', 'hotmail.com', 'sun.com', 'insiq.us', 'smokesdirect.com', 'netscape.net', 'hotmail.com', 'mail.ru', 'bennewitz.com', 'slack.net', 'diva.ie', 'rogers.com', 'insiq.us', 'ia.net', 'email2.qves.net', 'deepeddy.com', '2ubh.com', 'linkcreations.com.mx', 'ximian.com', 'yahoo.com', 'chinchilla.freeserve.co.uk', 'yahoo.ca', 'cse.ucsc.edu', 'trafficmagnet.com', 'permafrost.net', 'hotmail.com', 'talios.com', 'mad.scientist.com', '2ubh.com', 'example.com', 'argote.ch', 'monkey.org', 'cunniffe.net', 'acm.org', 'ordersomewherechaos.com', 'isppan.waw.pl', 'hotmail.com', 'hushmail.com', 'eudoramail.com', 'prodigy.net', 'rpmforge.net', 'reply2.azoogle.com', 'zanshin.com', 'earthlink.net', 'bignet.net', 'sendgreatoffers.com', 'yahoo.co.uk', 'deepeddy.com', 'mixmail.com', 'hotmail.com', 'mymail.dk', 'yahoo.com', 'abptrade.com.br', 'mindupmerchants.com', 'insiq.us', 'caramail.com', 'canada.com', 'earthlink.com', 'yahoo.com', 'ckloiber.com', 'netzero.com', 'ebuilt.com', 'cse.ucsc.edu', 'acm.org', 'insiq.us', 'leitl.org', 'emailrewardz.email-publisher.com', 'bibsam.kb.se', 'frugaljoe.com', 'camperquake.de', 'yahoo.com', 'sendgreatoffers.com', 'mithral.com', 'web.de', 'yahoo.com', 'orchidserve.com', 'cheapsmoking.com', 'hp.com', 'netscape.net', 'freeuk.com', 'perl.org', 'slack.net', 'aol.com', 'l5.newnamedns.com', 'site-personals.com', 'ordersomewherechaos.com', 'bestirishmusic.com', 'cse.ucsc.edu', 'mithral.com', 'and.ie', 'flashmail.com', '2ubh.com', 'fastmail.fm', 'coachinvest.com', 'softhome.net', 'europeaninternet.com', 'lycos.com', 'hotmail.com', 'dogma.slashnull.org', 'playful.com', 'insiq.us', 'msn.com', 'listmgmt.com', 'hotmail.com', 'hotmail.com', 'eudoramail.com', 'eudoramail.com', 'evergo.net', 'frogstone.net', 'ebonylust4free.com', 'example.com', 'securepro.com.hk', 'canada.com', 'amazon.com', 'dbsinfo.com', 'xo.net', 'webinfo.fi', 'eudoramail.com', 'swi.hu', 'terra.es', 'msn.com', 'cse.ucsc.edu', 'yahoo.com', 'hotmail.com', 'mx05.serveit21.com', 'yahoo.co.uk', 'books', 'slack.net', 'nationwidemortgage.us', 'redseven.de', 'canada.com', 'techmonkeys.net', 'zenmarketing.net', 'w3.org', 'quinlan.colo.netbauds.net', 'yahoo.com', 'deepeddy.com', 'mad.scientist.com', 'hotmail.com', 'excite.com', 'aa.alles.or.jp', 'site-personals.com', '360cn.com', 'excite.com', 'mailme.dk', 'ms22.hinet.net', 'eircom.net', '37.com', 't-online.de', 'insiq.us', 'perl.org', 'fastmail.fm', '2ubh.com', 'mithral.com', 'hotmail.com', 'wu-wien.ac.at', 'deepeddy.com', '2ubh.com', 'canada.com', 'sendgreatoffers.com', 'rocinante.com', 'alumni.caltech.edu', 'l11.newnamedns.com', 'ximian.com', 'srv0.ems.ed.ac.uk', 'argote.ch', 'msn.com', 'slack.net', 'sendgreatoffers.com', 'kssp.upd.edu.ph', 'slack.net', 'example.com', 'frogstone.net', 'nationwidemortgage.us', 'redbrick.dcu.ie', 'insiq.us', 'firemail.de', 'consultant.com', 'terra.es', 'ebuilt.com', 'hotmail.com', 'tcd.ie', 'cs.helsinki.fi', 'mad.scientist.com', 'acm.org', 'permafrost.net', 'cse.ucsc.edu', 'msn.com', 'barrera.org', 'aol.com', 'deisedesign.com', 'hotmail.com', 'example.com', 'email2.qves.net', 'hotmail.com', 'juno.com', 'cas.org', 'sendgreatoffers.com', 'physik.fu-berlin.de', 'mchp.siemens.de', 'feinsteins.net', 'rpmforge.net', 'hottmail.com', 'cs.com', 'insiq.us', 'srv0.ems.ed.ac.uk', 'hotmail.com', 'thphys.may.ie', 'insurancemail.net', 'yahoo.com', 'tradesignals.com', 'purplehotel.com', 'cse.ucsc.edu', 'net-temps.com', 'msn.com', 'motorola.com', 'asia.com', 'argote.ch', 'itsmobile.com', 'hotmail.com', 'easyadpost.com', 'sendgreatoffers.com', 'frogstone.net', '2ubh.com', 'mithral.com', 'teleweb.at', 'yahoo.com', 'mail.banirh.com', 'indigo.ie', 'hotmail.com', 'example.com', 'munnari.oz.au', 'forum.dk', 'geocities.com', '2ubh.com', 'bigfoot.com', 'mithral.com', 'bellsouth.net', 'mithral.com', 'excite.com', 'linux.ie', 'linuxmafia.com', 'esatclear.ie', 'ibd.pe.kr', 'hotmail.com', 'yahoo.com', 'aol.com', 'perkel.com', 'emxd.legally.com', 'l13.newnamedns.com', 'hellerwhirligigs.com', 'shipwright.com', 'awod.com', 'lancsmail.com', '44yes.onlineisbest.com', 'yahoo.com', 'uol.com.br', 'slack.net', 'yahoo.com', 'yahoo.com', 'techdirt.com', '99-81.com', 'mail.com', 'steorn.com', 'fastmail.fm', 'k1-web.com', 'insurancemail.net', 'subdimension.com', 'example.com', 'example.com', 'io.com', 'permafrost.net', 'panix.com', 'world.std.com', 'hotmail.com', 'ca.com', 'canada.com', 'insiq.us', 'best.com', 'example.com', 'mithral.com', 'hotmail.com', 'mithral.com', 'terra.es', 'deepeddy.com', 'mx2.1premio.com', 'cameltoelovers.com', 'permafrost.net', 'timesten.com', 'deersoft.com', 'networksonline.com', '1starnet.com', 'best.com', 'roscom.com', 'ireland.sun.com', 'earthlink.net', 'mithral.com', 'freeuk.com', 'topsail.org', 'hotmail.com', 'swirly.com', 'dogma.slashnull.org', 'alumni.caltech.edu', 'baesystems.com']\n",
      "\n",
      "Encoded Domains:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder # for email domain\n",
    "import re\n",
    "\n",
    "# # Function to extract domain using regex\n",
    "def extract_domain(email):\n",
    "    match = re.search(r'@([\\w.-]+)', email)  # Matches domain after @\n",
    "    return match.group(1).lower() if match else 'unknown'\n",
    "\n",
    "# Apply function to emails\n",
    "sample_train_domain = X_train['From'] # print(sample_train_domain)\n",
    "domains = [extract_domain(email) for email in sample_train_domain] #print(domains) \n",
    "domain_reshaped = np.array(domains).reshape(-1, 1) # Requires 2D dimension \n",
    "\n",
    "\n",
    "# Encode the domain using OrdinalEncoder\n",
    "OneHot_Encoder = OneHotEncoder()\n",
    "sample_train_domain_encoded = OneHot_Encoder.fit_transform(domain_reshaped)\n",
    "\n",
    "# Print the encoded values\n",
    "print(\"Original Domains:\")\n",
    "print(domains)\n",
    "print(\"\\nEncoded Domains:\")\n",
    "print(sample_train_domain_encoded.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class EmailDomainEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # Initialize OneHotEncoder\n",
    "        self.encoder = OneHotEncoder()\n",
    "        self.domains = None  # Placeholder for domains\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_domain(email):\n",
    "        \"\"\"\n",
    "        Extract the domain from an email address using regex.\n",
    "        If no domain is found, return 'unknown'.\n",
    "        \"\"\"\n",
    "        match = re.search(r'@([\\w.-]+)', email)  # Matches domain after @\n",
    "        return match.group(1).lower() if match else 'unknown'\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Extract domains from the email addresses in X and fit the OneHotEncoder.\n",
    "        \"\"\"\n",
    "        # Extract domains from email addresses\n",
    "        self.domains = [self.extract_domain(email) for email in X]\n",
    "        # Reshape domains for encoding\n",
    "        domain_reshaped = np.array(self.domains).reshape(-1, 1)\n",
    "        # Fit the encoder\n",
    "        self.encoder.fit(domain_reshaped)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform the email addresses in X into encoded domain vectors.\n",
    "        \"\"\"\n",
    "        # Extract domains from email addresses\n",
    "        domains = [self.extract_domain(email) for email in X]\n",
    "        # Reshape domains for encoding\n",
    "        domain_reshaped = np.array(domains).reshape(-1, 1)\n",
    "        # Transform using the fitted encoder\n",
    "        return self.encoder.transform(domain_reshaped).toarray()\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the encoder and transform the email addresses in one step.\n",
    "        \"\"\"\n",
    "        return super().fit_transform(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Domains:\n",
      "['redpie.com', 'ee.ed.ac.uk', 'barrera.org', 'mail.com', 'none.com', 'yahoo.com', 'example.com', 'example.com', 'indiatimes.com', 'docserver.cac.washington.edu', 'qu.to', 'wanadoo.fr', 'silcom.com', 'iol.ie', 'arabia.com', 'insiq.us', 'punkass.com', 'ig.com.br', 'noskillz.com', 'email.com', 'barrera.org', 'iol.ie', 'yahoo.com', 'svanstrom.com', 'example.com', 'hotmail.com', 'permafrost.net', 'sunglasses.com', 'mithral.com', 'insiq.us', 'subdimension.com', 'slack.net', 'caramail.com', 'evergo.net', 'insiq.us', 'shipwright.com', 'cursor-system.com', 'techmonkeys.net', 'framesetup.com', 'example.com', 'reset.jp', 'netnoteinc.com', 'eircom.net', 'yelsew.com', 'etang.com', 'interszkola.pl', 'shipwright.com', 's3.serveimage.com', 'infinetivity.com', 'iol.ie', 'att.net', 'deepeddy.com', 'eecs.berkeley.edu', 'hotmail.com', 'slack.net', 'alltel.net', 'mx03.readyserve21.com', 'btamail.net.cn', 'corvil.com', 'argote.ch', 'frogstone.net', 'tuatha.org', 'srv0.ems.ed.ac.uk', 'accesocero.es', 'tuatha.org', '99-81.com', 'clubi.ie', 'hotmail.com', '2ubh.com', 'chinaemail.net', 'endeavors.com', 'firemail.de', 'mobiusvc.com', 'shipwright.com', 'canada.com', 'bellsouth.net', 'eircom.net', 'yahoo.com', 'bacalhau.com.br', 'mail.banirh.com', 'mail.com', 'endeavors.com', 'terra.es', 'bestirishmusic.com', 'alumni.caltech.edu', 'hotmail.com', 'dogma.slashnull.org', 'hotmail.com', 'earthlink.net', 'petting-zoo.net', 'bluemail.dk', 'eecs.berkeley.edu', 'sunglasses.com', 'caramail.com', 'sbox.tu-graz.ac.at', 'enews.com.tw', 'flashmail.com', 'email2.qves.net', 'cse.ucsc.edu', 'shipwright.com', 'barrera.org', 'eudoramail.com', 'usa.net', 'aol.com', 'munnari.oz.au', 'yahoo.com', 'yahoo.fr', 'yahoo.fr', 'hotmail.com', '360cn.com', 'sendgreatoffers.com', 'frugaljoe.com', 'yahoo.com', 'yahoo.com', 'insiq.us', 'bennewitz.com', 'hotmail.com', 'ckloiber.com', 'terra.es', 'aol.com', 'perl.org', 'baesystems.com', 'corvil.com', '2ubh.com', 'yahoo.com', 'srv0.ems.ed.ac.uk', 'flashmail.com', 'ulysees.com', 'caramail.com', 'l8.newnamedns.com', 'munnari.oz.au', 'acsmsupplies.com', 'baesystems.com', 'friendsearch.com', 'lycos.com', 'ckloiber.com', 'stevek.com', 'top10.bestoffersonthenet.com', 'cheapsmoking.com', 'yahoo.com', 'yahoo.com', 'frogstone.net', 'bigfoot.com', 'leitl.org', 'srv0.ems.ed.ac.uk', 'lbedford.org', 'endeavors.com', 'hotmail.com', 'yahoo.com', 'physik.fu-berlin.de', 'sendgreatoffers.com', 'barrera.org', 'slack.net', 'l1.newnamedns.com', 'waider.ie', 'canada.com', 'best.com', 'hackwatch.com', 'yahoo.com', 'maxtor.com', 'mithral.com', 'frogstone.net', 'excite.com', 'barrera.org', 'hotmail.com', 'evergo.net', 'victoria.tc.ca', 'spinfinder.com', '2ubh.com', 'mail.com', 'gmx.at', 'perl.org', 'example.com', 'endeavors.com', 'eclipse.co.uk', 'r2-dvd.org', 's3.serveimage.com', 'torchlake.com', 'hotmail.com', 'l6.newnamedns.com', 'netscape.net', 'ucla.edu', 'punkass.com', 'maktoob.com', 'ucd.ie', 'srv0.ems.ed.ac.uk', 'canada.com', 'purplehotel.com', 'srv0.ems.ed.ac.uk', 'subdimension.com', 'linkgift.net', 'kamakiriad.com', 'canada.com', 'utt.ro', 'example.com', 'yahoo.com', 'sri.com', 'frugaljoe.com', 'spinfinder.com', 'georgia.co.jp', 'aol.com', 'pobox.com', 'cb.offermonkey.com', 'aernet.ru', 'dracnet.es', 'terra.es', 'webstakes.com', 'netscape.net', 'best.com', 'netnoteinc.com', 'yahoo.com', 'lycos.com', 'no.hostname.specified', 'eudoramail.com', '2ubh.com', 'framesetup.com', 'runbox.com', 'mail.gr', 'dogma.slashnull.org', 'l1.newnamedns.com', '2ubh.com', '2ubh.com', 'yahoo.com', 'ucd.ie', 'site-personals.com', 'hotmail.com', 'example.com', 'ee.ed.ac.uk', 'lanminds.com', 'example.com', 'techmonkeys.net', '2ubh.com', 'cse.ucsc.edu', 'magnesium.net', 'vccomputers.ie', 'welho.com', 'silcom.com', 'ul.ie', 'munnari.oz.au', 'panix.com', 'yahoo.com', 'ee.ed.ac.uk', 'top13.bestoffersonthenet.com', 'flashmail.com', 'sendgreatoffers.com', 'davicom.co.kr', 'chel.elektra.ru', 'missouri.co.jp', 'tuatha.org', 'yahoo.com', 'l5.newnamedns.com', 'martyrs.com.au', 'rediffmail.com', 'aol.com', 'endeavors.com', 'privacyright.com', 'eudoramail.com', 'flashmail.com', 'carrey.adgrafix.com', 'ianbell.com', 'ee.ed.ac.uk', 'cs.helsinki.fi', 'hotmail.com', 'hotmail.com', 'iafrica.com', 'rpmforge.net', 'slack.net', '2ubh.com', 'panasas.com', 'netscape.net', 'panix.com', 'slack.net', 'deepeddy.com', 'yahoo.com', 'evergo.net', 'leitl.org', 'juno.com', 'webstakes.com', 'kolaymail.com', 'abigclick.zzn.com', 'wanadoo.fr', 'hellerwhirligigs.com', 'waider.ie', 'magnesium.net', 'hotmail.com', 'offerclubmail.com', 'shipwright.com', 'slack.net', 'leitl.org', 'linuxmafia.com', 'srv0.ems.ed.ac.uk', 'megamail.pt', 'bluemail.dk', 'hotmail.com', 'aminvestments.com', 'shipwright.com', 'hp.com', 'permafrost.net', 'victoria.tc.ca', 'insiq.us', 'hotmail.com', 'jmason.org', 'egwn.net', 'waider.ie', 'hotmail.com', 'yahoo.com', 'hotmail.com', 'yahoo.com', 'mithral.com', 'wu-wien.ac.at', 'mymail.dk', 'wstoddard.com', 'linuxmafia.com', 'libero.it', 'topmail.dk', 'egwn.net', 'netscape.net', 'hotmail.com', 'iki.fi', 'mx03.readyserve21.com', 'aminvestments.com', 'lineone.net', 'redseven.de', 'freeuk.com', 'r2-dvd.org', '2ubh.com', '99-81.com', 'risingtidestudios.com', 'mithral.com', 'reply2.azoogle.com', 'ie.suberic.net', 'flashmail.com', '2ubh.com', 'hotmail.com', '2ubh.com', 'cheapsmoking.com', 'trackbike.com', 'ryanairmail.com', 'tuatha.org', 'hotmail.com', 'srv0.ems.ed.ac.uk', 'baesystems.com', 'eecs.berkeley.edu', 'redbrick.dcu.ie', 'munnari.oz.au', 'srv0.ems.ed.ac.uk', 'netscape.net', 'aol.com', 'l7.newnamedns.com', 'mindupmerchants.com', 'waider.ie', 'kamakiriad.com', 'pathname.com', 'newyork.com', 'mithral.com', 'aol.com', 'aol.com', 'hotmail.com', 'redbrick.dcu.ie', 'mad.scientist.com', 'deepeddy.com', 'orchidserve.com', 'yahoo.ca', 'mindspring.com', 'angelfire.com', 'rpmforge.net', 'eire.com', 'isppan.waw.pl', 'mithral.com', 'hughes-family.org', 'hotmail.com', 'hotmail.com', 'linuxworks.com.au', 'cursor-system.com', 'insiq.us', 'linkgift.net', 'slack.net', 'pobox.com', 'hotmail.com', 'monkey.org', 'argote.ch', 'idirect.net', 'bluemail.dk', 'ordersomewherechaos.com', 'mad.scientist.com', 'desertmail.com', 'synteligent.com', 'ttnet.net.tr', 'meritsolutions.ie', 'hotmail.com', 'caramail.com', 'bestirishmusic.com', 'waider.ie', 'eircom.net', 'insiq.us', 'eudoramail.com', 'cheerful.com', 'insiq.us', 'rpmforge.net', 'acm.org', 'actionsports.co.uk', 'caramail.com', 'msn.com', 'mediaunspun.imakenews.net', 'srv0.ems.ed.ac.uk', 'netsoc.ucd.ie', 'linux.ie', 'yahoo.com', 'yahoo.com', 'srv0.ems.ed.ac.uk', 'jtauber.com', 'terra.es', 'bluemail.dk', 'yahoo.com', 'ckloiber.com', 'hushmail.com', 'abigclick.zzn.com', 'hotmail.com', 'businez.com', 'europeaninternet.com', 'yahoo.com', 'rs.128.ne.jp', 'homeport.org', 'insiq.us', 'pobox.com', 'imail.ru', 'argote.ch', 'bellsouth.net', 'yahoo.com', 'r2-dvd.org', 'yahoo.co.uk', '360cn.com', 's3.serveimage.com', 'truthmail.com', 'best.com', 'linuxmafia.com', 'websitetracker.com', 'mail.com', 'ee.ed.ac.uk', 'esatclear.ie', 'insiq.us', 'example.com', 'post.com', 'wasptech.com', 'deepeddy.com', 'panix.com', 'mail.com', 'panix.com', 'barrera.org', 'usa.com', 'frugaljoe.com', '2nd-world.fr', 'hotmail.com', 'hotmail.com', 'l4.newnamedns.com', 'sendgreatoffers.com', 'lanminds.com', 'ant.eupvg.upc.es', 'yahoo.com', 'lists.tilw.net', 'fiaz.co.yu', 'pobox.com', 'totalise.co.uk', 'baesystems.com', 'caramail.com', 'sendgreatoffers.com', 'yahoo.com', 'example.com', '2ubh.com', 'consultant.com', 'eircom.net', 'redpie.com', 'frogstone.net', 'flashmail.com', 'webnote.net', 'hotmail.com', 'bigpond.com', 'r2-dvd.org', 'acm.org', '2ubh.com', 'exchange.ie.ml.com', '37.com', 'munnari.oz.au', 'insiq.us', 'datcon.co.uk', 'excite.com', 'dcu.ie', 'home-based-business.de', 'eware.com', 'mlug.missouri.edu', 'enenkio.org', 'hotmail.com', 'zip.com.au', '2ubh.com', 'deutsche-bank.de', 'eudoramail.com', 'sendgreatoffers.com', 'yahoo.com', 'ianbell.com', 'hotmail.com', 'staunton.ie', 'hotmail.com', 'sun.com', 'insiq.us', 'smokesdirect.com', 'netscape.net', 'hotmail.com', 'mail.ru', 'bennewitz.com', 'slack.net', 'diva.ie', 'rogers.com', 'insiq.us', 'ia.net', 'email2.qves.net', 'deepeddy.com', '2ubh.com', 'linkcreations.com.mx', 'ximian.com', 'yahoo.com', 'chinchilla.freeserve.co.uk', 'yahoo.ca', 'cse.ucsc.edu', 'trafficmagnet.com', 'permafrost.net', 'hotmail.com', 'talios.com', 'mad.scientist.com', '2ubh.com', 'example.com', 'argote.ch', 'monkey.org', 'cunniffe.net', 'acm.org', 'ordersomewherechaos.com', 'isppan.waw.pl', 'hotmail.com', 'hushmail.com', 'eudoramail.com', 'prodigy.net', 'rpmforge.net', 'reply2.azoogle.com', 'zanshin.com', 'earthlink.net', 'bignet.net', 'sendgreatoffers.com', 'yahoo.co.uk', 'deepeddy.com', 'mixmail.com', 'hotmail.com', 'mymail.dk', 'yahoo.com', 'abptrade.com.br', 'mindupmerchants.com', 'insiq.us', 'caramail.com', 'canada.com', 'earthlink.com', 'yahoo.com', 'ckloiber.com', 'netzero.com', 'ebuilt.com', 'cse.ucsc.edu', 'acm.org', 'insiq.us', 'leitl.org', 'emailrewardz.email-publisher.com', 'bibsam.kb.se', 'frugaljoe.com', 'camperquake.de', 'yahoo.com', 'sendgreatoffers.com', 'mithral.com', 'web.de', 'yahoo.com', 'orchidserve.com', 'cheapsmoking.com', 'hp.com', 'netscape.net', 'freeuk.com', 'perl.org', 'slack.net', 'aol.com', 'l5.newnamedns.com', 'site-personals.com', 'ordersomewherechaos.com', 'bestirishmusic.com', 'cse.ucsc.edu', 'mithral.com', 'and.ie', 'flashmail.com', '2ubh.com', 'fastmail.fm', 'coachinvest.com', 'softhome.net', 'europeaninternet.com', 'lycos.com', 'hotmail.com', 'dogma.slashnull.org', 'playful.com', 'insiq.us', 'msn.com', 'listmgmt.com', 'hotmail.com', 'hotmail.com', 'eudoramail.com', 'eudoramail.com', 'evergo.net', 'frogstone.net', 'ebonylust4free.com', 'example.com', 'securepro.com.hk', 'canada.com', 'amazon.com', 'dbsinfo.com', 'xo.net', 'webinfo.fi', 'eudoramail.com', 'swi.hu', 'terra.es', 'msn.com', 'cse.ucsc.edu', 'yahoo.com', 'hotmail.com', 'mx05.serveit21.com', 'yahoo.co.uk', 'books', 'slack.net', 'nationwidemortgage.us', 'redseven.de', 'canada.com', 'techmonkeys.net', 'zenmarketing.net', 'w3.org', 'quinlan.colo.netbauds.net', 'yahoo.com', 'deepeddy.com', 'mad.scientist.com', 'hotmail.com', 'excite.com', 'aa.alles.or.jp', 'site-personals.com', '360cn.com', 'excite.com', 'mailme.dk', 'ms22.hinet.net', 'eircom.net', '37.com', 't-online.de', 'insiq.us', 'perl.org', 'fastmail.fm', '2ubh.com', 'mithral.com', 'hotmail.com', 'wu-wien.ac.at', 'deepeddy.com', '2ubh.com', 'canada.com', 'sendgreatoffers.com', 'rocinante.com', 'alumni.caltech.edu', 'l11.newnamedns.com', 'ximian.com', 'srv0.ems.ed.ac.uk', 'argote.ch', 'msn.com', 'slack.net', 'sendgreatoffers.com', 'kssp.upd.edu.ph', 'slack.net', 'example.com', 'frogstone.net', 'nationwidemortgage.us', 'redbrick.dcu.ie', 'insiq.us', 'firemail.de', 'consultant.com', 'terra.es', 'ebuilt.com', 'hotmail.com', 'tcd.ie', 'cs.helsinki.fi', 'mad.scientist.com', 'acm.org', 'permafrost.net', 'cse.ucsc.edu', 'msn.com', 'barrera.org', 'aol.com', 'deisedesign.com', 'hotmail.com', 'example.com', 'email2.qves.net', 'hotmail.com', 'juno.com', 'cas.org', 'sendgreatoffers.com', 'physik.fu-berlin.de', 'mchp.siemens.de', 'feinsteins.net', 'rpmforge.net', 'hottmail.com', 'cs.com', 'insiq.us', 'srv0.ems.ed.ac.uk', 'hotmail.com', 'thphys.may.ie', 'insurancemail.net', 'yahoo.com', 'tradesignals.com', 'purplehotel.com', 'cse.ucsc.edu', 'net-temps.com', 'msn.com', 'motorola.com', 'asia.com', 'argote.ch', 'itsmobile.com', 'hotmail.com', 'easyadpost.com', 'sendgreatoffers.com', 'frogstone.net', '2ubh.com', 'mithral.com', 'teleweb.at', 'yahoo.com', 'mail.banirh.com', 'indigo.ie', 'hotmail.com', 'example.com', 'munnari.oz.au', 'forum.dk', 'geocities.com', '2ubh.com', 'bigfoot.com', 'mithral.com', 'bellsouth.net', 'mithral.com', 'excite.com', 'linux.ie', 'linuxmafia.com', 'esatclear.ie', 'ibd.pe.kr', 'hotmail.com', 'yahoo.com', 'aol.com', 'perkel.com', 'emxd.legally.com', 'l13.newnamedns.com', 'hellerwhirligigs.com', 'shipwright.com', 'awod.com', 'lancsmail.com', '44yes.onlineisbest.com', 'yahoo.com', 'uol.com.br', 'slack.net', 'yahoo.com', 'yahoo.com', 'techdirt.com', '99-81.com', 'mail.com', 'steorn.com', 'fastmail.fm', 'k1-web.com', 'insurancemail.net', 'subdimension.com', 'example.com', 'example.com', 'io.com', 'permafrost.net', 'panix.com', 'world.std.com', 'hotmail.com', 'ca.com', 'canada.com', 'insiq.us', 'best.com', 'example.com', 'mithral.com', 'hotmail.com', 'mithral.com', 'terra.es', 'deepeddy.com', 'mx2.1premio.com', 'cameltoelovers.com', 'permafrost.net', 'timesten.com', 'deersoft.com', 'networksonline.com', '1starnet.com', 'best.com', 'roscom.com', 'ireland.sun.com', 'earthlink.net', 'mithral.com', 'freeuk.com', 'topsail.org', 'hotmail.com', 'swirly.com', 'dogma.slashnull.org', 'alumni.caltech.edu', 'baesystems.com']\n",
      "\n",
      "Encoded Domains:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "# Sample data (replace X_train['From'] with actual data)\n",
    "sample_train_domain = X_train['From']\n",
    "\n",
    "# Instantiate the encoder\n",
    "domain_encoder = EmailDomainEncoder()\n",
    "\n",
    "# Fit and transform the sample data\n",
    "encoded_domains = domain_encoder.fit_transform(sample_train_domain)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original Domains:\")\n",
    "print(domain_encoder.domains)\n",
    "print(\"\\nEncoded Domains:\")\n",
    "print(encoded_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <span style=\"color:orange\"> word2vec: </span> convert the text to numerical representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1\n",
    "                            for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)),shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 10 stored elements and shape (3, 11)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(word_count)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ilug': 1,\n",
       " 'modem': 2,\n",
       " 'problems': 3,\n",
       " 'zzzzteana': 4,\n",
       " 'coming': 5,\n",
       " 'firestorm': 6,\n",
       " 'holiday': 7,\n",
       " 'season': 8,\n",
       " 'number': 9,\n",
       " 'begin': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    (\"email_to_wordcount\", CustomEmailTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer()),\n",
    "])\n",
    "# preprocessing_pipeline.fit_transform(X_train_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 1, expected 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      4\u001b[0m domain_attrib \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m final_preprocessing_pipeline \u001b[38;5;241m=\u001b[39m ColumnTransformer([\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m,preprocessing_pipeline,content_attrib),\n\u001b[1;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain\u001b[39m\u001b[38;5;124m'\u001b[39m,EmailDomainEncoder(),domain_attrib)\n\u001b[1;32m      9\u001b[0m ])\n\u001b[0;32m---> 11\u001b[0m final_data \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_preprocessing_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_data)\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1006\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record_output_indices(Xs)\n\u001b[0;32m-> 1006\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:1120\u001b[0m, in \u001b[0;36mColumnTransformer._hstack\u001b[0;34m(self, Xs, n_samples)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1115\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor a sparse output, all columns should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe a numeric or convertible to a numeric.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1118\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconverted_Xs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtocsr()\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     Xs \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39mtoarray() \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(f) \u001b[38;5;28;01melse\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m Xs]\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:742\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block([blocks], \u001b[38;5;28mformat\u001b[39m, dtype)\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblocks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_spmatrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/scipy/sparse/_construct.py:957\u001b[0m, in \u001b[0;36m_block\u001b[0;34m(blocks, format, dtype, return_spmatrix)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m brow_lengths[i] \u001b[38;5;241m!=\u001b[39m A\u001b[38;5;241m.\u001b[39m_shape_as_2d[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    954\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblocks[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,:] has incompatible row dimensions. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    955\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGot blocks[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].shape[0] == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39m_shape_as_2d[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    956\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbrow_lengths[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bcol_lengths[j] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    960\u001b[0m     bcol_lengths[j] \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39m_shape_as_2d[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 1, expected 2."
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "content_attrib = ['Subject','Content']\n",
    "domain_attrib = ['From']\n",
    "\n",
    "final_preprocessing_pipeline = ColumnTransformer([\n",
    "    ('content',preprocessing_pipeline,content_attrib),\n",
    "    ('domain',EmailDomainEncoder(),domain_attrib)\n",
    "])\n",
    "\n",
    "final_data = final_preprocessing_pipeline.fit_transform(X_train)\n",
    "print(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 804]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      4\u001b[0m log_clf \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m score\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:351\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_params_groups_deprecation(fit_params, params, groups)\n\u001b[0;32m--> 351\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/ollama/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 804]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "score = cross_val_score(log_clf, final_data, y_train, cv=3)\n",
    "score.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
